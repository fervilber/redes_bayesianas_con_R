---
title: "Aprendizaje supervisado en R"
author: "Fernando Villalba Bergado"
date: "3 de septiembre de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aprendizaje supervisado en R


El *aprendizaje supervisado** es una técnica usada en minería de datos, en la que se genera una función de pronóstico a partir del entrenamiento previo sobre datos. Es decir, aprendemos a partir de casos reales y extrapolamos el resultado a los futuros.

El proceso habitual consiste en dividir la muestra de datos en dos conjuntos, uno de entrenamiento y otro de test. Con los datos de entrenamiento ordenados convenientemente obtenemos un conjunto de vectores o pares de datos entrada-salida, siendo la salida lo que deseamos pronosticar. Entremanos al modelo para que aprende de los casos reales y genere una función de predicción.

Los pronósticos se pueden hacer mediante muchos modelos, por ejemplo con regresión lineal o logarítmica sobre los datos o también por clasificación que trata de agrupar los valores en conjuntos con características semejantes. 

Como hemos indicado, el objetivo del aprendizaje supervisado es el de crear una función capaz de predecir el valor correspondiente a cualquier objeto de entrada válida después de haber visto una serie de ejemplos, los datos de entrenamiento.

Existen diferntes algoritmos que abordan el problema de aprendizaje supervisado y tecnicas de minería de datos, en concreto vamos a explicar someramente los siguientes:

 - knn ((k-Nearest Neighbour Classification)
 - naive bayes

# knn (k-Nearest Neighbour Classification)
Esta función del paquete `class` realiza la clasificación de un conjunto de datos, veamos un ejemplo.

## Reconociendo una señal de tráfico con kNN
Después de varios viajes con un humano detrás del volante, es hora de que el auto que conduce solo intente el recorrido de prueba solo. Cuando comienza a alejarse, su cámara captura la siguiente imagen:

Señal de stop

¿Puedes aplicar un clasificador kNN para ayudar al auto a reconocer este signo?

Los signos del conjunto de datos se cargan en su espacio de trabajo junto con el marco de datos 

```{r}
# Cargamos el paquete class' que contienen la funcion knn
library(class)

# cargamos la base de datos de señales de trafico
signs<-read.csv("knn_traffic_signs.csv",header = TRUE)
head(signs)

# Creamos un vector de eiquetas
sign_types <- signs$sign_type
head(sign_types)

# Classificamos la proxima señal que cuyos datos se almacenan en next_sign
next_sign<-data.frame(
"r1"=204,
"g1"=227,
 "b1"=220,
 "r2"=196,
 "g2"=59,
 "b2"=51,
 "r3"=202,
 "g3"=67,
 "b3"=59,
 "r4"=204,
 "g4"=227,
 "b4"=220,
 "r5"=236,
 "g5"=250,
 "b5"=234,
 "r6"=242,
 "g6"=252,
 "b6"=235,
 "r7"=205,
 "g7"=148,
 "b7"=131,
 "r8"=190,
 "g8"=50,
 "b8"=43,
 "r9"=179,
 "g9"=70,
 "b9"=57,
 "r10"=242,
 "g10"=229,
 "b10"=212,
 "r11"=190,
 "g11"=50,
 "b11"=43,
 "r12"=193,
 "g12"=51,
 "b12"=44,
 "r13"=170,
 "g13"=197,
 "b13"=196,
 "r14"=190,
 "g14"=50,
 "b14"=43,
 "r15"=190,
 "g15"=47,
 "b15"=41,
 "r16"=165,
 "g16"=195,
 "b16"=196)

#signs[-1] quita la primera columna
knn(train = signs[c(-1,-2,-3)], test = next_sign, cl = sign_types)
```
## Explorando el conjunto de datos de señales de tráfico
Para comprender mejor cómo la función `knn()` al clasificar el stop anterior, puede ser útil examinar el conjunto de datos de entrenamiento que usamos.

Cada signo de calle observado previamente se dividió en una cuadrícula de 4x4, y el nivel rojo, verde y azul para cada uno de los 16 píxeles centrales se registra como el valor en ese punto central de cada un. El resultado es un conjunto de datos que registra el tipo de signo así como 16 x 3 = 48 propiedades de color de cada signo.

INSTRUCCIONES
100 XP
Use la función str () para examinar el conjunto de datos de signos.
Use la tabla () para contar el número de observaciones de cada tipo de signo pasándolo por la columna que contiene las etiquetas.
Ejecute el comando agregado agregado () para ver si el nivel rojo promedio puede variar según el tipo de signo.
```{r}
# Examine the structure of the signs dataset
str(signs)

# Count the number of signs of each type
table(signs$sign_type)

# Check r10's average red level by sign type
aggregate(r10 ~ sign_type, data = signs, mean)
```

## Clasificando una colección de señales de tráfico
Ahora que el vehículo autónomo se ha detenido con éxito por sí solo, su equipo se siente seguro al permitir que el automóvil continúe el recorrido de prueba.

El curso de prueba incluye 59 señales de tráfico adicionales divididas en tres tipos:

Señal de límite de velocidad de señal Señal de peatón de señal

Al finalizar la prueba, se le pedirá que mida el rendimiento general del automóvil al reconocer estos signos.

INSTRUCCIONES
100 XP
El paquete de clase y los letreros del conjunto de datos ya están cargados en su espacio de trabajo. También lo es el marco de datos test_signs, que contiene un conjunto de observaciones en las que probará su modelo.

Clasifica los datos test_signs usando knn().
Establecer tren igual a las observaciones en signos sin etiquetas.
Use test_signs para el argumento de la prueba, nuevamente sin etiquetas.
Para el argumento cl, usa el vector de etiquetas provisto para ti.
Use la tabla () para explorar el rendimiento del clasificador al identificar los tres tipos de signos.
Crea el vector signs_actual extrayendo las etiquetas de test_signs.
Pase el vector de predicciones y el vector de signos reales a la tabla () para cruzar tabularlos.
Calcule la precisión general del alumno kNN utilizando la función mean ().
```{r}
# Use kNN to identify the test road signs
sign_types <- signs$sign_type
signs_pred <- knn(train =signs[-1], test =test_signs[-1], cl =sign_types)

# Create a confusion matrix of the actual versus predicted values
signs_actual <- test_signs$sign_type
table(signs_pred, signs_actual)

# Compute the accuracy
mean(signs_pred == signs_actual)
```

## k near neighbors
EJERCICIO
EJERCICIO
Probando otros valores 'k'
Por defecto, la función knn () en el paquete de clase usa solo el vecino más cercano.

Establecer un parámetro k permite que el algoritmo considere vecinos cercanos adicionales. Esto amplía la colección de vecinos que votarán en la clase predicha.

Compare los valores k de 1, 7 y 15 para examinar el impacto en la precisión de la clasificación de señales de tráfico.

INSTRUCCIONES
100 XP
El paquete de clase ya está cargado en su espacio de trabajo junto con los signos de conjunto de datos y signos_prueba. El objeto signs_actual contiene los verdaderos valores de los signos.

Calcule la precisión del modelo predeterminado k = 1 usando el código dado.
Modifique la llamada a la función knn() configurando k = 7.
Revise el código una vez más configurando k = 15 y compare los tres valores de precisión.

```{r}
# Compute the accuracy of the baseline model (default k = 1)
k_1 <- knn(train = signs[-1], test = signs_test[-1], cl = signs$sign_type)
mean(k_1 == signs_actual)

# Modify the above to set k = 7
k_7 <- knn(train = signs[-1], test = signs_test[-1], cl = signs$sign_type, k = 7)
mean(k_7 == signs_actual)

# Set k = 15 and compare to the above
k_15 <- knn(train = signs[-1], test = signs_test[-1], cl = signs$sign_type, k = 15)
mean(k_15 == signs_actual)
```

# Naive Bayes
Naive Bayes es un modelo de pronóstico simple que usa la probabilidad Bayesiana. El modelo aplica la probabilidad condicionada de BAYES para obtener un resultado de pronostico.

El modelo bayesiano de probabilidad condicionada se representa como:
$P(A|B) = P(A \cap B) / P(B)$

Es decir, la probabilidad de que se de el caso A dado B es igual a la probabilidad de la intersección de A con B partido la probabilidad de B.

El paquete `naivebayes` contienen las formulas necesarias para estos modelos.

## Calculo real de probabilidad condicional
Con la base de datos de `locations.csv` vamos a experimentar el calculo real de probabilidad condicional. Veamos como se calcula la probabilidad de estar en la oficina sabiendo que es un día laborable.

La base de datos `locations.csv`  contienen información de la ubicación en la que se encontraba una persana en diferentes momentos y días durante unas cuantas semanas.

```{r}
# leemos la base de datos
where9am<-read.csv("locations.csv",header = TRUE)
head(where9am)

# P(A)= en la oficina 
p_A <- nrow(subset(where9am, location == "office")) / nrow(where9am)

# P(B)= dia laborable
p_B <- nrow(subset(where9am, daytype == "weekday")) / nrow(where9am)

# P(A interseccion B) observada
p_AB <- nrow(subset(where9am, where9am$location == "office" & where9am$daytype == "weekday")) / nrow(where9am)

# P(A | B) = P de A sabiendo que ha ocurrido B
p_A_given_B <- p_AB / p_B
p_A_given_B
```

Vamos a calcular estos mismos datos con el modelo de naivebayes, usando el paquete `naivebayes`

```{r}
    # Cargamos el paquete
        library(naivebayes)
    # leemos la base de datos
    #where9am<-read.csv("locations.csv",header = TRUE)
    #head(where9am)

    # Construimos un modelo de predicción de la localización
    # en función del tipo de dia
        locmodel <- naive_bayes(location ~ daytype, data = where9am)
        plot(locmodel)
    # sabemos que es un dia laborable
        hecho<-data.frame(daytype="weekday")
    # predecimos las probabilidades
        predict(locmodel,hecho,type = "class")
        predict(locmodel,hecho, type="prob")
    # sabemos que es un dia laborable
        hecho<-data.frame(daytype="weekend")        
```

Como hemos visto la salidad del modelo puede ser la simple predicción o tambien la lista completa de probabilidades estimadas añadiendo el argumento `type="prob`.

Los modelos se pueden complicar aplicando fórmulas de variables dentro del primer argumento de la fórmula. Por ejemplo podemos crear un modelo de predicción de la ubicación, no solo según el tipo de día sino en función de la hora del día también, que es otra variable de los datos.
Es tambien importante añadir el argumento de laplace, que implica suponer que al menos se da un caso de cada combinación posible. Si no se hace esto pueden rechazarse hipotesis que aunque con probabilidad baja, se pueden dar.

**tengo problemas con el resultado de estas funiones ya que no funciona bien**

```{r}
    # paquete de naivebayes 
        require(naivebayes)
    # posibles ubicaciones
        unique(where9am$location)
    # posibles horas del dia    
        unique(where9am$hourtype)
        str(where9am)
        table(where9am$hourtype)
    # construimos un nuevo modelo de bayes que nos de la localización
    # en función del día y de la hora, añadimos laplace=1, para crear al menos un caso de 
    #     
        locmodel <- naive_bayes(location ~ daytype + hourtype, data = where9am,laplace=1)
    # vemos una representacion del modelo    
        plot(locmodel)
    
    # queremos conocer cual es la localización más probable un
    # un dia laborable por la mañana
    # creamos una data frame con estos datos    
        hecho<-data.frame(daytype="weekday",hourtype="morning")

    # Predecir localización
        predict(locmodel,hecho)
        predict(locmodel,hecho, type = "prob")

    # Predict Brett's location on a weekday evening
        hecho2<-data.frame(daytype='weekday',hourtype='night')
#        subset(where9am, daytype == "weekend" & hourtype =="night")
#        where9am[where9am$daytype=="weekend" & where9am$hourtype=="evening",]

        predict(locmodel,hecho2)
        predict(locmodel,hecho2, type="prob")
```

me tiene loco este modelo, pues las predicciones no son buenas, no sé cual es el error pero no da bien.

```{r}
# modelo general

library(naivebayes)
locmodel <- naive_bayes(location ~ ., data = where9am)
plot(locmodel1)

weekday_evening<-data.frame(daytype="weekday",hourtype="night")

predict(locmodel,weekday_evening) 
predict(locmodel1,weekday_evening, type = "prob")
# no puede ser que el fin de semana tarde esté en la oficina, algo no va bien
weekend_afternoon<-data.frame(daytype="weekend",hourtype="afternoon")
predict(locmodel,weekend_afternoon)
```


### Corrección de laplace
Esta corrección evita que la probabilidad de eventos no datados arrastre el resto de probabilidades asociadas a cero. Pues la simplificación del modelo ingenuo de bayes es que no calcula las probabilidades cruzaas completas sino que supone que todos los sucesos son independientes y calcula la probabilidad condicionada como multiplicación de la probabilidad de sus ocurrencias.

Vamos a comparar las probabilidades dadas por el modelo normal, y el que añadimos laplace=1, es decir añadimos un suceso a cada combinacion de sucesos. 

```{r}
# The 'naivebayes' package is loaded into the workspace already
# The Naive Bayes location model (locmodel) has already been built

# Observe the predicted probabilities for a weekend afternoon
predict(locmodel,weekend_afternoon , type="prob")

# Build a new model using the Laplace correction
locmodel2 <- naive_bayes(location ~ daytype + hourtype, data = where9am, laplace=1)

# Observe the new predicted probabilities for a weekend afternoon
predict(locmodel2,weekend_afternoon)
predict(locmodel2,weekend_afternoon , type="prob")
```

### Categorización
Un problema del uso de naive_bayes es que usa datos categorizados por lo que con origenes de datos numericos continuos hay que realizar una pre categorización o agrupamiento y elegir unas categorías o zonas que definan las mismas antes de aplicar el modelo. Sería imposible aplicarlo al conjunto entero continuo pues saldrían infinidad de casos cruzados y hay que simplificar.

Hay muchas herramientas en R para hacer esto, usando cuantiles, o bolsas de palabras en casos numéricos.

# Predicciones binarias por regresión
las binarias son un caso particular de regresión en las que se muestran algunos problemas de predición. El primero es que al usar regresión lineal para datos binarios(0,1) (si, no) la linea nos proporciona un ajuste muy malo a la realidad de los datos.

Una forma de evitarlo es usando la predicción logaritmica, que aplica un ajuste log a los datos entre 0, 1 y da mejores resultados:

```{r eval=FALSE}
m <- glm(y ~ x1 + x2 + x3,
           data = my_dataset,
           family = "binomial")

prob <- predict(m, test_dataset,
          type = "response")

pred <- ifelse(prob > 0.50, 1, 0)

```

## Construir modelos simples de regresión logística
El conjunto de datos de donantes contiene 93.462 ejemplos de personas enviadas por correo en una solicitud de recaudación de fondos para veteranos militares paralizados. La columna `donated` es 1 si la persona hizo una donación en respuesta al correo y 0 en caso contrario. Este resultado binario será la variable dependiente para el modelo de regresión logística.

Las columnas restantes son características de los posibles donantes que pueden influir en su comportamiento de donación. Estas son las variables independientes del modelo.

Al construir un modelo de regresión, a menudo es útil formar una hipótesis sobre qué variables independientes serán predictivas de la variable dependiente. La columna `bad_address`, que se establece en 1 para una dirección de correo no válida y 0 en caso contrario, parece que podría reducir las posibilidades de una donación. Del mismo modo, uno podría sospechar que el interés religioso (`interest_religion`) y el interés en los asuntos de veteranos (`interest_veterans`) se asociarían con mayores donaciones caritativas.

En este ejercicio, usará estos tres factores para crear un modelo simple de comportamiento de donación.

INSTRUCCIONES
100 XP
La tabla donors está disponible en su espacio de trabajo.

Examine a los donantes usando la función str ().
Cuente el número de ocurrencias de cada nivel de la variable donada usando la función table ().
Ajuste un modelo de regresión logística utilizando la interfaz de fórmula y las tres variables independientes descritas anteriormente.
Llame a glm () con la fórmula como primer argumento y el marco de datos como argumento de datos.
Guarde el resultado como donation_model.
Resume el objeto modelo con summary ().
```{r}
donors<-read.csv("donors.csv",header = TRUE)
head(donors)
str(donors)

# Explore the dependent variable
table(donors$donate)
require(naivebayes)
# Build the donation model
donation_model <- glm(donated ~ bad_address + interest_religion + interest_veterans, data = donors, family = "binomial")

# Summarize the model results
summary(donation_model)

```
## Hacer una predicción binaria
En el ejercicio anterior, utilizó la función glm() para construir un modelo de regresión logística del comportamiento del donante. Al igual que con muchos de los métodos de aprendizaje automático de R, puede aplicar la función de predicción() al objeto modelo para predecir el comportamiento futuro. Por defecto, predic() produce predicciones en términos de log odds a menos que se especifique type = "response". Esto convierte las probabilidades del registro en probabilidades.

Debido a que un modelo de regresión logística estima la probabilidad del resultado, depende de usted determinar el umbral en el que la probabilidad implica la acción

Uno debe equilibrar los extremos de ser demasiado cauteloso frente a ser demasiado agresivo. Por ejemplo, si solicitara solo a las personas con una probabilidad de donación del 99% o superior, es posible que se pierda a muchas personas con probabilidades estimadas más bajas que todavía eligen donar. Este equilibrio es particularmente importante a considerar para los resultados severamente desequilibrados, como en este conjunto de datos donde las donaciones son relativamente raras.


INSTRUCCIONES
Los donantes del conjunto de datos y el modelo donation_model ya están cargados en su espacio de trabajo.

Use la función de predicción () para estimar la probabilidad de donación de cada persona. Usa el argumento tipo para obtener probabilidades. Asigna las predicciones a una nueva columna llamada donation_prob.
Encuentre la probabilidad real que una persona promedio donaría al pasar la función mean () a la columna apropiada del marco de datos de los donantes.
Use ifelse () para predecir una donación si su probabilidad de donación prevista es mayor que el promedio. Asigna las predicciones a una nueva columna llamada donation_pred.
Use la función mean () para calcular la precisión del modelo.

```{r}
# Estimate the donation probability
donors$donation_prob <- predict(donation_model, type = "response")

head(donors)
# Find the donation probability of the average prospect
mean(donors$donated)
# establecemos un umbral de clasificación de que si es >50,4% la persona donará
# Predict a donation if probability of donation is greater than average (0.0504)
donors$donation_pred <- ifelse(donors$donation_prob > 0.0504, 1, 0)
head(donors)
# Calculate the model's accuracy
mean(donors$donation_pred == donors$donated)

# cual es la % de acierto si el modelo es predecir siempre que no hay donación.
mean(donors$donated == 0)
# así que ojo, hay que valorar el acierto dentro del conjunto pequeño sino estamos falseando esultados
```
## Cálculo de curvas ROC y AUC
Como se ha visto en el ejemplo anterior, cuando uno de los eventos es muy raro predecir el evento opuesto conlleva un gran porcentaje d aciertos, lo que hay que vigilar y entender.

en estos casos es mejor sacrificar los aciertos generales en favor de concentrar los sobre uno de los resultados, el más raro.


Los ejercicios anteriores han demostrado que la precisión es una medida muy engañosa del rendimiento del modelo en conjuntos de datos desequilibrados. Hacer una gráfica del desempeño del modelo ilustra mejor la compensación entre un modelo que es demasiado agresivo y uno que es demasiado pasivo.

En este ejercicio, creará una curva ROC y calculará el área bajo la curva (AUC) para evaluar el modelo de regresión logística de las donaciones que construyó anteriormente.

INSTRUCCIONES
100 XP
Los donantes de conjuntos de datos con la columna de probabilidades pronosticadas, donation_prob, ya están cargados en su espacio de trabajo.

Cargue el paquete pROC.
Cree una curva ROC con roc () y las columnas de donaciones reales y pronosticadas. Almacene el resultado como ROC.
Usa plot () para dibujar el objeto ROC. Especifique col = "azul" para colorear la curva azul.
Calcule el área bajo la curva con auc ().
```{r}
# Load the pROC package
library(pROC)

# Create a ROC curve
ROC <- roc(donors$donated, donors$donation_prob)

# Plot the ROC curve
plot(ROC, col = "blue")

# Calculate the area under the curve (AUC)
auc(ROC)
```
Awesome job! Based on this visualization, the model isn't doing much better than baseline— a model doing nothing but making predictions at random

## que hacer con los NA
```{r}
# create gender factor
my_data$gender <- factor(my_data$gender,
                         levels = c(0, 1, 2),
                         labels = c("Male", "Female", "Other"))

# interaction of obesity and smoking
glm(disease ~ obesity * smoking,
      data = health,
      family = "binomial")
```

Codificación de características categóricas
A veces, un conjunto de datos contiene valores numéricos que representan una característica categórica.

En el conjunto de datos de donantes, wealth_rating usa números para indicar el nivel de riqueza del donante:

0 = Desconocido
1 = bajo
2 = Medio
3 = Alto
Este ejercicio ilustra cómo preparar este tipo de característica categórica y examina su impacto en un modelo de regresión logística.

INSTRUCCIONES
100 XP
Los donantes del marco de datos se cargan en su espacio de trabajo.

Cree un factor a partir del numérico wealth_rating con etiquetas como se muestra arriba pasando la función factor () a la columna que desea convertir, los niveles individuales y las etiquetas.
Use relevel () para cambiar la categoría de referencia a Medium. El primer argumento debería ser tu columna de factores.
Cree un modelo de regresión logística utilizando la columna wealth_rating para predecir donaciones y muestre el resultado con summary ().

```{r}
# Convert the wealth rating to a factor
donors$wealth_rating <- factor(donors$wealth_rating, levels = c(0,1,2,3), labels = c("Unknown","Low","Medium","High"))

# Use relevel() to change reference category
donors$wealth_rating <- relevel(donors$wealth_rating, ref = "Medium")
m<-glm(donated ~ wealth_rating ,
      data = donors,
      family = "binomial")
# See how our factor coding impacts the model
summary(m)
```
## Manejo de datos faltantes
Algunos de los posibles donantes tienen datos de edad faltantes. Desafortunadamente, R excluirá cualquier caso con valores de NA al construir un modelo de regresión.

Una solución alternativa es reemplazar o imputar los valores perdidos con un valor estimado. Después de hacerlo, tageambién puede crear un indicador de datos faltantes para modelar la posibilidad de que los casos con datos faltantes sean diferentes de los que carecen.

INSTRUCCIONES
100 XP
Los donantes del marco de datos se cargan en su espacio de trabajo.

Use el resumen () sobre los donantes para encontrar la edad promedio de los prospectos con datos no perdidos.
Utilice ifelse () y la prueba es.na (donadores $ edad) para imputar el promedio (redondeado a 2 lugares decimales) para los casos con edad faltante.
Cree una variable ficticia binaria llamada missing_age que indique la presencia de datos faltantes utilizando otra llamada ifelse () y la misma prueba.

```{r}
# Find the average age among non-missing values
summary(donors$age)

# Impute missing age values with mean(age)
donors$imputed_age <- ifelse(is.na(donors$age),61.65,donors$age)

# Create missing value indicator for age
donors$missing_age <- ifelse(is.na(donors$age),1,0)
```

## Construyendo un modelo más sofisticado
Uno de los mejores predictores de donaciones futuras es una historia de regalos recientes, frecuentes y grandes. En términos de comercialización, esto se conoce como R / F / M:

Recency
Frequency
Money

Es muy probable que los donantes que no han administrado tanto recientemente como con frecuencia realicen nuevamente; en otras palabras, el impacto combinado de reciente y frecuencia puede ser mayor que la suma de los efectos por separado.

Debido a que estos predictores juntos tienen un mayor impacto en la variable dependiente, su efecto conjunto debe modelarse como una interacción.

INSTRUCCIONES
100 XP
El conjunto de datos de donantes se ha cargado para usted.

Cree un modelo de regresión logística de donado en función del dinero más la interacción de lo reciente y la frecuencia. Use * para agregar el término de interacción.
Examine el resumen del modelo () para confirmar que se agregó el efecto de interacción.
Guarde las probabilidades pronosticadas del modelo como rfm_prob. Use la función de predicción () y recuerde establecer el argumento de tipo.
Trace una curva ROC usando la función roc (). Recuerde, esta función toma la columna de resultados y el vector de predicciones.
Calcule el AUC para el nuevo modelo con la función auc () y compare el rendimiento con el modelo más simple.

```{r}
# Build a recency, frequency, and money (RFM) model
rfm_model <- glm(donated ~ money + recency* frequency ,data = donors,family = "binomial")

# Summarize the RFM model to see how the parameters were coded
summary(rfm_model)

# Compute predicted probabilities for the RFM model
rfm_prob <- predict(rfm_model, type = "response")

# Plot the ROC curve and find AUC for the new model
library(pROC)
ROC <- roc(donors$donated, rfm_prob)
plot(ROC, col = "red")
auc(ROC)
```

## Construyendo un modelo de regresión gradual
En ausencia de experiencia en la materia, la regresión gradual puede ayudar con la búsqueda de los predictores más importantes del resultado de interés.

En este ejercicio, utilizará un enfoque gradual progresivo para agregar predictores al modelo uno por uno hasta que no se vea ningún beneficio adicional.

INSTRUCCIONES
100 XP
El conjunto de datos de donantes se ha cargado para usted.

Use la interfaz de fórmula R con glm () para especificar el modelo base sin predictores. Establezca la variable explicativa igual a 1.
Use la interfaz de la fórmula R nuevamente con glm () para especificar el modelo con todos los predictores.
Aplique el paso () a estos modelos para realizar una regresión progresiva hacia adelante. Establezca el primer argumento en null_model y establezca direction = "forward". Esto puede tardar un tiempo (hasta 10 o 15 segundos) ya que su computadora tiene que adaptarse a varios modelos diferentes para realizar una selección gradual.
Cree un vector de probabilidades pronosticadas utilizando la función de predicción ().
Trace la curva ROC con roc () y plot () y calcule el AUC del modelo por pasos con auc ().

```{r}
# Specify a null model with no predictors
null_model <- glm(donated ~1, data = donors, family = "binomial")

# Specify the full model using all of the potential predictors
full_model <- glm(donated ~ ., data = donors, family = "binomial")

# Use a forward stepwise algorithm to build a parsimonious model
step_model <- step(null_model, scope = list(lower = null_model, upper = full_model), direction = "forward")

# Estimate the stepwise donation probability
step_prob <- predict(step_model, type = "response")

# Plot the ROC of the stepwise model
library(pROC)
ROC <- roc(donors$donated, step_prob)
plot(ROC, col = "red")
auc(ROC)
```

# Árboles de decisión

Un arbol de decisión es una estructura ramificada que muestra las diferentes opciones y sus consecuencias. Los puntos en los que hay que tomar decisiones se muestran como *nodos*, las ramas unen estos nodos y finalmente las decisiones finales son como las hojas, donde el camino termina (tambien se denominan nodos termiales).

Vamos a ver algunos paquetes que permiten hacer árboles de decisión en R.

## rpart
rpart es una librería que hace arboles de decision a partir de datos. La función rpart crea, a partir de un conjunto de datos, y de una fórmula de predición, un árbol de decisión que puede usarse para predecir con la función `predict`

```{r}
# building a simple rpart classification tree
library(rpart)
loans<-read.csv("loans.csv", header = TRUE)
head(loans)
m <- rpart(outcome ~ loan_amount + credit_score, data = loans, method = "class")

# making predictions from an rpart tree
p <- predict(m, test_data, type = "class")

locmodel <- rpart(location ~ daytype + hourtype, data = where9am, method = "class")
weekend_afternoon<-data.frame(daytype="weekend",hourtype="afternoon")
weekdy_morning<-data.frame(daytype="weekday",hourtype="morning")
#plot(locmodel)
predict(locmodel, weekend_afternoon)

predict(locmodel, weekdy_morning) #, type = "class")
```

## crear un arbol de decisión simple

El conjunto de datos de préstamos `loan` contiene los datos de 11312 personas elegidas al azar que fueron solicitantes y luego recibieron préstamos de Lending Club, una compañía de préstamos entre particulares establecida en los Estados Unidos.

Utilizará un árbol de decisiones para tratar de aprender patrones en el resultado de estos préstamos (reembolsados o no) en función del monto del préstamo solicitado y el puntaje de crédito en el momento de la solicitud.

Luego, vea cómo las predicciones del árbol difieren para un solicitante con buen crédito versus uno con mal crédito.
```{r}
loans<-read.csv("loans.csv",header = TRUE, strip.white=TRUE)
# strip.white=TRUE sirve para hacer trim al leer y descartr los espacios en blanco de cad ini y fin de palabra
head(loans)
good_credit<-data.frame(   
  loan_amount="LOW",
  emp_length="10+ years",        
  home_ownership="MORTGAGE",   
  income="HIGH",            
  loan_purpose="major_purchase",
  debt_to_income="AVERAGE",    
  credit_score="HIGH",     
  recent_inquiry="NO",    
  delinquent="NEVER",        
  credit_accounts="MANY",   
  bad_public_record="NO", 
  credit_utilization="LOW",
  past_bankrupt="NO",     
  outcome="repaid"                
)
bad_credit<-data.frame(   
  loan_amount="LOW",
  emp_length="6 - 9 years",        
  home_ownership="RENT",   
  income="MEDIUM",            
  loan_purpose="car",
  debt_to_income="LOW",    
  credit_score="LOW",     
  recent_inquiry="YES",    
  delinquent="NEVER",        
  credit_accounts="FEW",   
  bad_public_record="NO", 
  credit_utilization="HIGH",
  past_bankrupt="NO",     
  outcome="repaid"                
)

# Load the rpart package
library(rpart)

# Build a lending model predicting loan outcome versus loan amount and credit score
loan_model <- rpart(outcome ~ loan_amount + credit_score, data = loans, method = "class", control = rpart.control(cp = 0))

# Make a prediction for someone with good credit
predict(loan_model, good_credit, type = "class")

# Make a prediction for someone with bad credit
predict(loan_model, bad_credit, type = "class")


# VEAMOS EL ARBOL DE DECISION
loan_model

# Load the rpart.plot package
library(rpart.plot)

# Plot the loan_model with default settings
rpart.plot(loan_model)

# Plot the loan_model with customized settings
rpart.plot(loan_model, type = 3, box.palette = c("red", "green"), fallen.leaves = TRUE)
```

## overfitting
los arboles de decision son problematicos con la sobreestimacion de parametros, pues la metodología obliga siempre a divisiones paralelas a los ejes de variables y pude generar muchos, pese a que el modelo puede ser muy sencillo. Por eso es siempre conveniente crear un conjunto de datos de entrenamiento y otro de testado final.

###Crear conjuntos de datos de prueba aleatorios
Antes de construir un modelo de préstamo más sofisticado, es importante mantener una parte de los datos del préstamo para simular qué tan bien va a predecir los resultados de los futuros solicitantes de préstamos.

Como se muestra en la siguiente imagen, puede usar el 75% de las observaciones para el entrenamiento y el 25% para probar el modelo.

Diagrama de árbol de decisión

La función `sample()` se puede usar para generar una muestra aleatoria de filas para incluir en el conjunto de entrenamiento. Simplemente proporciónele el número total de observaciones y el número necesario para el entrenamiento.

Use el vector resultante de identificadores de filas para subconjuntos de los préstamos en conjuntos de datos de capacitación y prueba.

```{r}
# Determine the number of rows for training
nrow(loans)
0.75*nrow(loans)
# Create a random sample of row IDs
sample_rows <- sample(nrow(loans), 0.75*nrow(loans))

# Create the training dataset
loans_train <- loans[sample_rows,]

# Create the test dataset
loans_test <- loans[-sample_rows,]
```

### Construyendo y evaluando un árbol más grande
Anteriormente, creaba un árbol de decisión simple que utilizaba el puntaje de crédito del solicitante y el monto del préstamo solicitado para predecir el resultado del préstamo.

Lending Club tiene información adicional sobre los solicitantes, como el estado de la propiedad de la vivienda, la duración del empleo, el propósito del préstamo y las quiebras anteriores, que pueden ser útiles para hacer predicciones más precisas.

Usando todos los datos disponibles del solicitante, construya un modelo de préstamo más sofisticado usando el conjunto de datos de entrenamiento aleatorio creado previamente. Luego, use este modelo para hacer predicciones sobre el conjunto de datos de prueba para estimar el rendimiento del modelo en futuras solicitudes de préstamos.
```{r}
# Grow a tree using all of the available applicant data
loan_model <- rpart(outcome ~ ., data = loans_train, method = "class", control = rpart.control(cp = 0))

# Make predictions on the test dataset
loans_test$pred <- predict(loan_model,loans_test, type = "class")

# Examine the confusion matrix
table(loans_test$pred,loans_test$outcome)

# Compute the accuracy on the test dataset
mean(loans_test$pred==loans_test$outcome)
```

## ajustar los arboles a la medida correcta

Dada la facilidad con la que un arbol se complica muchos paquetes tienen funciones especiales para cortar, limitar y optimizar el tamaño y la forma de los arboles.
Por ejemplo rpart lo puede hacer con control linitando la profuncidad del arbol y el numero de divisiones máximo.

el proceso puede hacerse antes o despues de crear el arbol, en lo que llamamos pre y post poda o control.
En concreto la librería rpart contiene un parametro que hemos estado usando el cp, que controla la complejidad del arrbol.

```{r}
# pre-pruning with rpart
library(rpart)
prune_control <- rpart.control(maxdepth = 30, minsplit = 20)

m <- rpart(repaid ~ credit_score + request_amt,
           data = loans,
           method = "class",
           control = prune_control)

# post-pruning with rpart
m <- rpart(repaid ~ credit_score + request_amt,
           data = loans,
           method = "class")

plotcp(m)

m_pruned <- prune(m, cp = 0.20)
```
### Previniendo árboles crecidos
El árbol cultivado en el conjunto completo de datos del solicitante creció hasta ser extremadamente grande y extremadamente complejo, con cientos de divisiones y nodos de hojas que contenían solo un puñado de solicitantes. Este árbol sería casi imposible de interpretar por un oficial de préstamos.

Usando los métodos previos a la poda para la detención temprana, puede evitar que un árbol se vuelva demasiado grande y complejo. Vea cómo las opciones de control de rpart para la profundidad máxima del árbol y el recuento mínimo de división afectan el árbol resultante.

```{r}
# Grow a tree with maxdepth of 6
loan_model <- rpart(outcome ~ ., data = loans_train, method = "class", control = rpart.control(cp = 0, maxdepth = 6))

# Compute the accuracy of the simpler tree
loans_test$pred <- predict(loan_model, loans_test, type = "class")
mean(loans_test$pred == loans_test$outcome)

# Grow a tree with minsplit of 500
loan_model2 <- rpart(outcome ~ ., data = loans_train, method = "class", control = rpart.control(cp = 0, minsplit = 500))

# Compute the accuracy of the simpler tree
loans_test$pred2 <- predict(loan_model2, loans_test, type = "class")
mean(loans_test$pred2 == loans_test$outcome)
```

### Creando un árbol bien podado
Evitar que un árbol crezca hasta el final puede llevarlo a ignorar algunos aspectos de los datos o perder tendencias importantes que pueda haber descubierto más adelante.
Al usar la poda posterior, puede hacer crecer intencionalmente un objeto grande y complejo y luego podarlo para que sea más pequeño y más eficiente más adelante.

En este ejercicio, tendrá la oportunidad de construir una visualización del rendimiento del árbol frente a la complejidad, y usar esta información para podar el árbol a un nivel apropiado.

```{r}
# Grow an overly complex tree
loan_model <- rpart(outcome ~ ., data = loans_train, method = "class", control = rpart.control(cp = 0))

# Examine the complexity plot
plotcp(loan_model)

# Prune the tree
loan_model_pruned <- prune(loan_model, cp = 0.0014)

# Compute the accuracy of the pruned tree
loans_test$pred <- predict(loan_model_pruned, loans_test, type = "class")
mean(loans_test$pred == loans_test$outcome)
```



# bosques de clasificación
la union de arboles de decision en conjunto con otros es uno de los métodos má seficientes de predicción y más usados hoy día para big dat.


En realidad lo que se hace es construir diferentes conjuntos de entrenamiento y de test sobre los mismos datos, lo que genera diferentes aroles de decisión sobre los mismos datos, la union de estos arboles de diferentes complejidades y con datos de origen distintos aunque del mismo conjunto de datos da origen a un random forest, cuya principal caracteristica es que crea modelos mucho más robustos de los que se obrtendrían creando un solo arbol de deicion complejo sobre los mismos datos. Cuando se unen estos arboles se hace el prodeso de ensemble o ensamblado de modelos que genera predicciones robustas.


Los grupos de árboles de clasificación se pueden combinar en un conjunto que genera una única predicción al permitir que los árboles "voten" sobre el resultado.

```{r}
# building a simple random forest
library(randomForest)
m <- randomForest(repaid ~ credit_score + request_amt, data = loans,
             ntree = 500,    # number of trees in the forest
             mtry = sqrt(p)) # number of predictors (p) per tree

# making predictions from a random forest
p <- predict(m, test_data)

```



### Construyendo un modelo de bosque aleatorio
A pesar del hecho de que un bosque puede contener cientos de árboles, hacer crecer un bosque de árboles de decisión es tal vez incluso más fácil que crear un solo árbol muy afinado.

Usando el paquete randomForest, construya un bosque al azar y vea cómo se compara con los árboles individuales que construyó previamente.

Tenga en cuenta que debido a la naturaleza aleatoria del bosque, los resultados pueden variar ligeramente cada vez que crea el bosque.


```{r}
# Load the randomForest package
library(randomForest)

# Build a random forest model
loan_model <- randomForest(outcome ~ ., data = loans_train) 

# Compute the accuracy of the random forest
loans_test$pred <- predict(loan_model,loans_test)
mean(loans_test$pred == loans_test$outcome)
```

