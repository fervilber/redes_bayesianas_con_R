# INFERENCIA BAYESIANA


## Funciones generadoras
son las funciones que definen el modelo inicial, y generan los numeros o hechos supuestos. Es la formulaci√≥n matem√°tica del modelo.





```{r}
prop_success<-0.1
size<-100
#‚ò∫ simulaci√≥n
data<-c()
for(i in 1:size){
    data[i]<-runif(1,min=0, max=1)<prop_success
}
data
data<-as.numeric(data) 
```

el modelo de generaci√≥n anterior es lo mismo que el binomial, por lo que lo podemos simplificar usano la funci√≥n `rbinom`

```{r}
n_samples <- 100000
n_ads_shown <- 100
proportion_clicks <- 0.1
n_visitors <- rbinom(n_samples, size = n_ads_shown, 
                     prob = proportion_clicks)
```

## valores anteriores
este es un ejemplo practico. tenemos un anuncio que poner en redes sociales para incrementar el trafico en nuestra web.

Sabemos que el 10% de las veces que sle el anuncio este es cliqueado.

```{r}
n_samples <- 100000
n_ads_shown <- 100
proportion_clicks <- 0.1
n_visitors <- rbinom(n_samples, size = n_ads_shown, 
                     prob = proportion_clicks)
```


remplazamos la incertidumbre que tenemos en ese 10% por una variable uniforme de 0 a 20%:
```{r}
# Update proportion_clicks
n_samples <- 100000
n_ads_shown <- 100
proportion_clicks <- runif(n = n_samples, min = 0.0, max = 0.2)
n_visitors <- rbinom(n = n_samples, size = n_ads_shown, prob = proportion_clicks)
#n_visitors <- rbinom(n = n_samples, size = n_ads_shown, prob = 0.1)

# Visualize the results
hist(proportion_clicks)
hist(n_visitors)
```
viendo estos histogramas nos damos cuenta de que la incertidumbre en el numeor de visitas finales al introducir una incertidumbre en el numero de clicks es grande.

## Evidencias
Los modelos nos generan muchos datos simulados que son previos a tener resultados o evidencias reales, por eso denominamos al data frame que continen los datos simulados con el modelo de generaci√≥n `prior`.
Si tenemos alguna evidencia cierta, la cosa cambia, pues sabemos ya un resultado cierto y podemos dar la vuelta con ese dato al modelo para mejorar la predicci√≥n.

```{r}
# Modelo de generaci√≥n de trafico en una web haciendo publicidad
n_samples <- 100000
n_ads_shown <- 100

# modelo de proporcion de clicks
proportion_clicks <- runif(n = n_samples, min = 0.0, max = 0.2)

# Modelo de generaci√≥n de visitantes
n_visitors <- rbinom(n = n_samples, size = n_ads_shown, prob = proportion_clicks)

# almacenamos en una tabla las simulaciones 
prior <- data.frame(proportion_clicks, n_visitors)
head(prior)
plot(prior)

library(ggplot2)
    ggplot(data=prior, aes(y=n_visitors, x= proportion_clicks))+
        geom_point()

library(ggvis)
prior %>% ggvis(~proportion_clicks,~n_visitors)

```

Imagina que la campa√±a de publicidad se ha realizado y que hemos obtenido exactamente 13 visitantes gracias a ella. Es decir que tenemos un dato una evidencia.

Con ella vamos ha hacer inferencia bayesiana, y lo primero es seleccionar en nuestro modelo generacional los casos en que el numeor de visitantes era igual a 13.

Filtramos `prior$n_visitors` para que obtener los datos concretos de 13 visitantes.
y vemos que histograma tiene la otra variable el (% de clicks) para este caso. 

```{r}
# Create the prior data frame
#prior <- data.frame(proportion_clicks, n_visitors)
head(prior)

# Create the posterior data frame
posterior<-prior[prior$n_visitors == 13, ]

head(posterior)
hist(posterior$proportion_clicks)
summary(posterior$proportion_clicks)
str(posterior$proportion_clicks)
length(posterior$proportion_clicks)
```
Como vemos la proporcion de clicks forma una distribuci√≥n que no es la uniforme que hemos supuesto al inicio de modelo.Lo que vemos es mas parecida a una normal y los valores est√°n alrrededor del  13,3% de clicks
Tenemos en esta simulaci√≥n `eval(length(posterior$proportion_clicks))` que podemos usar como evidencia, pues en todas ellas el resultado de numero de visitantes ha sido 13.

PAra ello asignamos como prio el valor de la evidencia posterior, remplazando los valores de nuemor de visitantes por lo que obtiene el modelo pero usando la otra variable % de clicks

```{r}
# Asignamos posterior a una nueva variable llamada prior
prior <- posterior
# Echamos un vistazo
head(prior)
# Remplazamos prior$n_visitors con nuevos valores simulados
n_samples <-  nrow(prior)
n_ads_shown <- 100

prior$n_visitors <- rbinom(n_samples, size = n_ads_shown,
                           prob = prior$proportion_clicks)
hist(prior$n_visitors)
# Calculate the probability that you will get 5 or more visitors
sum(prior$n_visitors >=5) / length(prior$n_visitors)
#hist(rbinom(10000, size = 100, prob = 0.2))
```


# Ejemplos

## uso de beta
la distribuci√≥n beta es muy adaptable a cualquier rango de datos que tengamos
Explore usando la distribuci√≥n Beta como una prioridad
La distribuci√≥n Beta es una distribuci√≥n de probabilidad √∫til cuando se desea la incertidumbre del modelo sobre un par√°metro limitado entre 0 y 1. Aqu√≠ se explorar√° c√≥mo los dos par√°metros de la distribuci√≥n Beta determinan su forma.

cuanto mayor sean los parametros m√°s concentrada en estar√° la muestra enel centro
```{r}
# veamos la forma de beta con ambos parametros 1
# Explore using the rbeta function
beta_sample <- rbeta(n = 1000000, shape1 = 1, shape2 = 1)
# Visualize the results
hist(beta_sample)
# es como uniforme

# CUANTO MAS ALTO LOS PARAMETROS MAS CENTRADA
beta_sample <- rbeta(n = 1000000, shape1 = 100, shape2 = 100)
# Visualize the results
hist(beta_sample)

# CUANTO MAS ALTO SEA el p1 mas cerca de 1 y cuanto mas alto el p2 mas cerca de cero
beta_sample <- rbeta(n = 1000000, shape1 = 100, shape2 = 1)
# Visualize the results
hist(beta_sample)
beta_sample <- rbeta(n = 1000000, shape1 = 1, shape2 = 10)
# Visualize the results
hist(beta_sample)

```
si nos dicen que los anuncios habitualmente estan en el 5% y algunas veces en el 2 y en el 8
```{r}
n_draws <- 100000
n_ads_shown <- 100

# Change the prior on proportion_clicks
#proportion_clicks <-  runif(n_draws, min = 0.0, max = 0.2)
proportion_clicks <-  runif(n_draws, min = 0.0, max = 0.2)
n_visitors <- rbinom(n_draws, size = n_ads_shown, 
         prob = proportion_clicks)
prior <- data.frame(proportion_clicks, n_visitors)
posterior <- prior[prior$n_visitors == 13, ]

# This plots the prior and the posterior in the same plot
par(mfcol = c(2, 1))
hist(prior$proportion_clicks, 
     xlim = c(0, 0.25))
hist(posterior$proportion_clicks, 
     xlim = c(0, 0.25))
```
```{r}
n_draws <- 100000
n_ads_shown <- 100
proportion_clicks <- runif(n_draws, min = 0.0, max = 0.2)
n_visitors <- rbinom(n = n_draws, size = n_ads_shown, 
                     prob = proportion_clicks)
prior <- data.frame(proportion_clicks, n_visitors)

# Create the posteriors for video and text ads
posterior_video <- prior[prior$n_visitors == 13, ]
posterior_text <- prior[prior$n_visitors == 6, ]

# Visualize the posteriors
hist(posterior_video$proportion_clicks, xlim = c(0, 0.25))
hist(posterior_text$proportion_clicks, xlim = c(0, 0.25))
```

Calculando la diferencia posterior
Los porcentajes posteriores de anuncios de video y texto se han incluido en un solo marco de datos posterior. El motivo de [1: 4000] se debe a que proporcionalmente, estos clics no tienen la misma longitud, lo que necesitan ser cuando se colocan en un marco de datos.

Ahora es el momento de calcular la distribuci√≥n de probabilidad posterior sobre la diferencia en la proporci√≥n de clics entre el anuncio de video y el anuncio de texto.
```{r}
posterior <- data.frame(
    video_prop = posterior_video$proportion_clicks[1:4000],
    text_prop  = posterior_text$proportion_click[1:4000])
    
# Calculate the posterior difference: video_prop - text_prop
posterior$prop_diff <- (posterior$video_prop - posterior$text_prop)

# Visualize prop_diff
hist(posterior$prop_diff)

# Summarize prop_diff
median(posterior$prop_diff)
sum(posterior$prop_diff>0)/length(posterior$prop_diff)
```

## decision analysis
Un peque√±o an√°lisis de decisi√≥n 1
Cada visitante gasta $ 2.53 en promedio, un anuncio de video cuesta $ 0.25 y un anuncio de texto cuesta $ 0.05. ¬°Imaginemos la ganancia probable al usar anuncios de video y anuncios de texto!

El marco de datos posterior contiene la distribuci√≥n de probabilidad sobre la proporci√≥n subyacente de clics para anuncios de video y anuncios de texto.

Agregue la columna posterior $ video_profit, que debe ser la distribuci√≥n de probabilidad sobre la ganancia promedio que obtendr√° al mostrar un anuncio de video. Es decir, la proporci√≥n subyacente de clics multiplicada por el gasto promedio menos el costo de mostrar el video.

```{r}
visitor_spend <- 2.53
video_cost <- 0.25
text_cost <- 0.05

# Add the column posterior$video_profit
posterior$video_profit<-posterior$video_prop*visitor_spend-video_cost
# Add the column posterior$text_profit
posterior$text_profit<-posterior$text_prop*visitor_spend-text_cost
# Visualize the video_profit and text_profit columns
hist(posterior$video_profit)
hist(posterior$text_profit)
```

## poison distribucion
nos da las distribucion media de click por unidad de tiempo

La distribuci√≥n de Poisson
La distribuci√≥n de Poisson simula un proceso donde el resultado es una cantidad de ocurrencias por d√≠a / a√±o / √°rea / unidad / etc. Antes de usarlo en un modelo Bayesiano, ¬°exploradlo!

INSTRUCCIONES 1/4

La distribuci√≥n de Poisson tiene un par√°metro, la cantidad promedio de eventos por unidad. En R puede simular desde una distribuci√≥n de Poisson utilizando rpois donde lambda es el n√∫mero promedio de ocurrencias:

rpois (n = 10000, lambda = 3)
Usa el c√≥digo de arriba para simular 10000 sorteos de una distribuci√≥n de Poisson, asigna el resultado a x.
Visualice x usando un histograma (hist).
```{r}
# Simulate from a Poisson distribution and visualize the result
x<-rpois(n = 10000, lambda = 3)
hist(x)
```
Digamos que maneja un puesto de helados y en d√≠as nublados, en promedio, vende 11.5 helados. Es un d√≠a nublado.

Cambia la llamada de rpois para visualizar la distribuci√≥n de probabilidad sobre cu√°ntos helados vender√°s.
```{r}
# Simulate from a Poisson distribution and visualize the result
x<-rpois(n = 10000, lambda = 11.5)
hist(x)
```

Todav√≠a es un d√≠a nublado y, lamentablemente, no alcanzar√°s un punto de equilibrio a menos que vendas 15 o m√°s helados.

Suponiendo que el modelo de Poisson es razonable, use x para calcular la probabilidad de que llegue a un punto de equilibrio.
Consejo: para esto, debe calcular qu√© proporci√≥n de muestras en x son> = 15

```{r}
# Simulate from a Poisson distribution and visualize the result
x<-rpois(n = 10000, lambda = 11.5)
hist(x)
sum(x>=15)/length(x)
```

##Clics por d√≠a en lugar de clics por anuncio
Cuando coloca un banner en el sitio de su amigo, obtiene 19 clics en un d√≠a, ¬øcu√°ntos clics diarios deber√≠a esperar generar en promedio? Ahora, modifique su modelo, una pieza a la vez, para calcular esto.

INSTRUCCIONES 1/4

A la derecha est√° el c√≥digo anterior para el modelo bayesiano binomial. Para acomodar los nuevos datos de banner, ahora va a cambiar el modelo para que use una distribuci√≥n de Poisson.

Comience reemplazando la distribuci√≥n anterior sobre proport_clicks por una anterior sobre mean_clicks. Realice una distribuci√≥n previa uniforme (runif) de 0 a 80 clics por d√≠a.

```{r}
# Change this model so that it uses a Poisson distribution instead
n_draws <- 100000
n_ads_shown <- 100
proportion_clicks <- runif(n_draws, min = 0.0, max = 0.2)
n_visitors <- rbinom(n_draws, size = n_ads_shown, 
                     prob = proportion_clicks)
                     
prior <- data.frame(proportion_clicks, n_visitors)
posterior <- prior[prior$n_visitors == 13, ]

# nuevo con cambios
# Change this model so that it uses a Poisson distribution instead
n_draws <- 100000

#proportion_clicks <- runif(n_draws, min = 0.0, max = 0.2)
mean_clicks<-runif(n_draws, min = 0.0, max = 80)
n_visitors <- rpois(n_draws,lambda=mean_clicks )
                     
prior <- data.frame(mean_clicks, n_visitors)
posterior <- prior[prior$n_visitors == 19, ]

hist(prior$mean_clicks)
hist(posterior$mean_clicks)

```
# probabilidad conceptos.

Cards and the sum rule
A standard French-suited deck of playing cards contains 52 cards; 13 each of hearts (‚ô•), spades (‚ô†), clubs (‚ô¶), and diamonds (‚ô£). Assuming that you have a well-shuffled deck in front of you, the probability of drawing any given card is 1/52 ‚âà 1.92%.

Tarjetas y la regla de suma

Una baraja est√°ndar de barajas para jugar contiene 52 cartas; 13 cada uno de corazones (‚ô•), espadas (‚ô†), palos (‚ô¶) y diamantes (‚ô£). Suponiendo que tienes una baraja bien barajada frente a ti, la probabilidad de robar una carta determinada es de 1/52 ‚âà 1.92%.Calcule la probabilidad de sacar cualquiera de los cuatro ases. Es decir, calcule la probabilidad de dibujar üÇ° o üÇ± o üÉÅ o üÉë usando la regla de 

```{r}
# Calculate the probability of drawing any of the four aces
# sacar cualquiera de los cuatrosde 4 ases
prob_to_draw_ace <- 4/52
# Calculate the probability of picking four aces in a row
prob_to_draw_four_aces <- 4/52*3/51*2/50*1/49
```
Utilice la regla del producto para calcular la probabilidad de elegir los cuatro ases en una fila desde la parte superior de un mazo bien barajado y as√≠gnelo a prob_to_draw_four_aces.


# proceso de inferencia competo

Vams a crear un grid con todas las posibilidades combimadas de probabilidad del modelo de generaci√≥n de anuncios y clicks

```{r}
n_ads_shown <- 100
proportion_clicks <- seq(0, 1, by = 0.01)
n_visitors <- seq(0, 100, by = 1)
pars <- expand.grid(proportion_clicks = proportion_clicks,
                    n_visitors = n_visitors)
head(pars)
pars$prior <- dunif(pars$proportion_clicks, min = 0, max = 0.2)
pars$likelihood <- dbinom(pars$n_visitors, 
    size = n_ads_shown, prob = pars$proportion_clicks)

# Add the column pars$probability and normalize it
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability/sum(pars$probability) 
```
```{r}
n_ads_shown <- 100
proportion_clicks <- seq(0, 1, by = 0.01)
n_visitors <- seq(0, 100, by = 1)
pars <- expand.grid(proportion_clicks = proportion_clicks,
                    n_visitors = n_visitors)
pars$prior <- dunif(pars$proportion_clicks, min = 0, max = 0.2)
pars$likelihood <- dbinom(pars$n_visitors, 
    size = n_ads_shown, prob = pars$proportion_clicks)
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)
# Condition on the data 
pars <- pars[pars$n_visitors==6,]
# Normalize again
pars$probability <- pars$probability/sum(pars$probability)
# Plot the posterior pars$probability
plot(x=pars$proportion_clicks, y=pars$probability, type = "h")
```

```{r}
#lo mismo simplificando c√≥digo
# Simplify the code below by directly conditioning on the data
n_ads_shown <- 100
proportion_clicks <- seq(0, 1, by = 0.01)
n_visitors <- 6
pars <- expand.grid(proportion_clicks = proportion_clicks,
                    n_visitors = n_visitors)
pars$prior <- dunif(pars$proportion_clicks, min = 0, max = 0.2)
pars$likelihood <- dbinom(pars$n_visitors, 
    size = n_ads_shown, prob = pars$proportion_clicks)
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)

pars$probability <- pars$probability / sum(pars$probability)
plot(pars$proportion_clicks, pars$probability, type = "h")
```

## rnorm, dnorm, and the weight of newborns
Here is a small data set with the birth weights of six newborn babies in grams.

c(3164, 3362, 4435, 3542, 3578, 4529)
```{r}
# Explore using rnorm and dnorm
mu <- 3700
sigma <- 500

weight_distr <- rnorm(n = 100000, mean = mu, sd = sigma)
hist(weight_distr, 60, xlim = c(0, 6000), col = "lightgreen")

# Explore using rnorm and dnorm
mu <- 3700
sigma <- 500
weight<-seq(from = 0, to =6000 , by =100 )
weight_distr <- dnorm(weight,mean = mu, sd = sigma)
hist(weight_distr, 60, xlim = c(0, 6000), col = "lightgreen")

# Explore using rnorm and dnorm
mu <- 3700
sigma <- 500
weight<-seq(from = 0, to =6000 , by =100 )
likelihood <- dnorm(weight,mean = mu, sd = sigma)
plot(x=weight,y=likelihood, type="h")
```



```{r}
# modelo de temprestura del lago al completo
temp <- c(19, 23, 20, 17, 23)
mu <- seq(8, 30, by = 0.5)
sigma <- seq(0.1, 10, by = 0.3)
pars <- expand.grid(mu = mu, sigma = sigma)
pars$mu_prior <- dnorm(pars$mu, mean = 18, sd = 5)
pars$sigma_prior <- dunif(pars$sigma, min = 0, max = 10)
pars$prior <- pars$mu_prior * pars$sigma_prior
for(i in 1:nrow(pars)) {
    likelihoods <- dnorm(temp, pars$mu[i], pars$sigma[i])
    pars$likelihood[i] <- prod(likelihoods)
}
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)
```


## lo mismo con zoombies:

```{r}
# The IQ of a bunch of zombies
iq <- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 46)
# Defining the parameter grid
pars <- expand.grid(mu = seq(0, 150, length.out = 100), 
                    sigma = seq(0.1, 50, length.out = 100))
# Defining and calculating the prior density for each parameter combination
pars$mu_prior <- dnorm(pars$mu, mean = 100, sd = 100)
pars$sigma_prior <- dunif(pars$sigma, min = 0.1, max = 50)
pars$prior <- pars$mu_prior * pars$sigma_prior
# Calculating the likelihood for each parameter combination
for(i in 1:nrow(pars)) {
  likelihoods <- dnorm(iq, pars$mu[i], pars$sigma[i])
  pars$likelihood[i] <- prod(likelihoods)
}
# Calculate the probability of each parameter combination
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)

#pintamos el resutado
library(lattice)
levelplot(probability ~ mu * sigma, data = pars)
```
## Muestreo desde el zombie posterior
Nuevamente, pars contiene el marco de datos que representa la distribuci√≥n de IQ zombie posterior que calcul√≥ anteriormente. El c√≥digo a la derecha dibuja muestra_indices: una muestra de n√∫meros de fila (√≠ndices a.k.a.) del posterior. ¬°Ahora, probemos de pars para calcular algunas medidas nuevas!

INSTRUCCIONES 1/4
25 XP
1
2
3
4
Use sample_indices para crear un nuevo marco de datos pars_sample de pars con las columnas mu y sigma extra√≠das de las filas indicadas por sample_indices.
Consejo: Si df es un marco de datos con muchas filas y columnas, aqu√≠ es c√≥mo extraer√≠a las filas 1, 3 y 1 (nuevamente), y las columnas llamadas "altura" y "peso":

df [c (1,3,1), c ("altura", "peso")]
```{r}
head(pars)
sample_indices <- sample( nrow(pars), size = 10000,
    replace = TRUE, prob = pars$probability)
head(sample_indices)

# Sample from pars to calculate some new measures
pars_sample <- pars[sample_indices, c("mu", "sigma")]

# Visualize pars_sample
hist(pars_sample$mu)
# Calculate the 0.025, 0.5 and 0.975 quantiles of pars_sample$mu
quantile(pars_sample$mu, c(0.025,0.5, 0.975))
# con esto tendriamos la media y los valores con 95% de confianza
```

# BEST
BEST es un aquete que ayuda a hacer inferencia estadistica.


```{r}
library(BEST)
iq <- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 46)
fit <- BESTmcmc(iq)
plot(fit)
```
## Los MEJORES modelos y zombies en una dieta
La prueba t es un procedimiento estad√≠stico cl√°sico que se usa para comparar los medios de dos conjuntos de datos. En 2013, John Kruschke desarroll√≥ una versi√≥n Bayesiana trucada de la prueba t que denomin√≥ BEST (que significa Estimaci√≥n bayesiana que reemplaza la prueba t). Probemos BEST como se implement√≥ en el paquete BEST.

Los zombis son est√∫pidos, pero t√∫ y tus colegas en el Laboratorio Nacional de Investigaci√≥n de Zombies est√°n interesados en c√≥mo la dieta afecta la inteligencia zombie. Has hecho un peque√±o experimento donde midiste el IQ de 10 zombies con una dieta regular y 10 zombis con una dieta basada en el cerebro. La hip√≥tesis es que los zombies que comen m√°s cerebros rinden mejor en las pruebas de cociente intelectual. A la derecha, los datos del experimento se colocan en las variables iq_brains e iq_regular.

Calcule la diferencia de medias en IQ entre los dos grupos tomando la media de iq_brains menos la media de iq_regular. Recuerde que mean (iq_brains) calcula la media de muestra de iq_brains.

```{r}
# The IQ of zombies on a regular diet and a brain based diet.
iq_brains <- c(44, 52, 42, 66, 53, 42, 55, 57, 56, 51)
iq_regular <- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 46)

# Calculate the mean difference in IQ between the two groups
mean(iq_brains)-mean(iq_regular)
# Fit the BEST model to the data from both groups
library(BEST)
best_posterior<-BESTmcmc(iq_brains, iq_regular)
# Plot the model result
plot(best_posterior)
```


# Ejemplo

en una clase se mide a 5 de los ni√±os la altura con el siguiente resultado:

altura<-c(120, 125, 140, 135, 133)

Se pide determinar la altura media de la clase con un 95% de probabilidad.
Usaremos el paquete BEST para estimar una funcion t (similar a la normal) que nos describa a partir de las evidencias de altura la media y desviaci√≥n t√≠pica.

```{r}

altura<-c(120, 125, 140, 135, 133)
mean(altura)

library(BEST)
best_posterior<-BESTmcmc(altura)
plot(best_posterior)
```


# dibujo
```{r}

library(ggplot2)

df<-data.frame(x=0,y=0)
param=0.9

for(i in 2:100) {
    df[i,1]<-df[i-1,1]-(0.1*i)*cos(i)
    df[i,2]<-df[i-1,2]+(0.1*i)*sin(i)
    }

ggplot(df,aes(x,y))+
    geom_polygon(fill="darkblue")+
    theme_void()


for(i in 2:100) {
    df[i,1]<-df[i-1,1]+(0.9*i^2)*cos(i^2)
    df[i,2]<-df[i-1,2]+(0.9*i^2)*sin(i^2)
    }
```

