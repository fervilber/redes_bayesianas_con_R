# INFERENCIA BAYESIANA


## Funciones generadoras
son las funciones que definen el modelo inicial, y generan los numeros o hechos supuestos. Es la formulación matemática del modelo.





```{r}
prop_success<-0.1
size<-100
#☺ simulación
data<-c()
for(i in 1:size){
    data[i]<-runif(1,min=0, max=1)<prop_success
}
data
data<-as.numeric(data) 
```

el modelo de generación anterior es lo mismo que el binomial, por lo que lo podemos simplificar usano la función `rbinom`

```{r}
n_samples <- 100000
n_ads_shown <- 100
proportion_clicks <- 0.1
n_visitors <- rbinom(n_samples, size = n_ads_shown, 
                     prob = proportion_clicks)
```

## valores anteriores
este es un ejemplo practico. tenemos un anuncio que poner en redes sociales para incrementar el trafico en nuestra web.

Sabemos que el 10% de las veces que sle el anuncio este es cliqueado.

```{r}
n_samples <- 100000
n_ads_shown <- 100
proportion_clicks <- 0.1
n_visitors <- rbinom(n_samples, size = n_ads_shown, 
                     prob = proportion_clicks)
```


remplazamos la incertidumbre que tenemos en ese 10% por una variable uniforme de 0 a 20%:
```{r}
# Update proportion_clicks
n_samples <- 100000
n_ads_shown <- 100
proportion_clicks <- runif(n = n_samples, min = 0.0, max = 0.2)
n_visitors <- rbinom(n = n_samples, size = n_ads_shown, prob = proportion_clicks)
#n_visitors <- rbinom(n = n_samples, size = n_ads_shown, prob = 0.1)

# Visualize the results
hist(proportion_clicks)
hist(n_visitors)
```
viendo estos histogramas nos damos cuenta de que la incertidumbre en el numeor de visitas finales al introducir una incertidumbre en el numero de clicks es grande.

## Evidencias
Los modelos nos generan muchos datos simulados que son previos a tener resultados o evidencias reales, por eso denominamos al data frame que continen los datos simulados con el modelo de generación `prior`.
Si tenemos alguna evidencia cierta, la cosa cambia, pues sabemos ya un resultado cierto y podemos dar la vuelta con ese dato al modelo para mejorar la predicción.

```{r}
# Modelo de generación de trafico en una web haciendo publicidad
n_samples <- 100000
n_ads_shown <- 100

# modelo de proporcion de clicks
proportion_clicks <- runif(n = n_samples, min = 0.0, max = 0.2)

# Modelo de generación de visitantes
n_visitors <- rbinom(n = n_samples, size = n_ads_shown, prob = proportion_clicks)

# almacenamos en una tabla las simulaciones 
prior <- data.frame(proportion_clicks, n_visitors)
head(prior)
plot(prior)

library(ggplot2)
    ggplot(data=prior, aes(y=n_visitors, x= proportion_clicks))+
        geom_point()

library(ggvis)
prior %>% ggvis(~proportion_clicks,~n_visitors)

```

Imagina que la campaña de publicidad se ha realizado y que hemos obtenido exactamente 13 visitantes gracias a ella. Es decir que tenemos un dato una evidencia.

Con ella vamos ha hacer inferencia bayesiana, y lo primero es seleccionar en nuestro modelo generacional los casos en que el numeor de visitantes era igual a 13.

Filtramos `prior$n_visitors` para que obtener los datos concretos de 13 visitantes.
y vemos que histograma tiene la otra variable el (% de clicks) para este caso. 

```{r}
# Create the prior data frame
#prior <- data.frame(proportion_clicks, n_visitors)
head(prior)

# Create the posterior data frame
posterior<-prior[prior$n_visitors == 13, ]

head(posterior)
hist(posterior$proportion_clicks)
summary(posterior$proportion_clicks)
str(posterior$proportion_clicks)
length(posterior$proportion_clicks)
```
Como vemos la proporcion de clicks forma una distribución que no es la uniforme que hemos supuesto al inicio de modelo.Lo que vemos es mas parecida a una normal y los valores están alrrededor del  13,3% de clicks
Tenemos en esta simulación `eval(length(posterior$proportion_clicks))` que podemos usar como evidencia, pues en todas ellas el resultado de numero de visitantes ha sido 13.

PAra ello asignamos como prio el valor de la evidencia posterior, remplazando los valores de nuemor de visitantes por lo que obtiene el modelo pero usando la otra variable % de clicks

```{r}
# Asignamos posterior a una nueva variable llamada prior
prior <- posterior
# Echamos un vistazo
head(prior)
# Remplazamos prior$n_visitors con nuevos valores simulados
n_samples <-  nrow(prior)
n_ads_shown <- 100

prior$n_visitors <- rbinom(n_samples, size = n_ads_shown,
                           prob = prior$proportion_clicks)
hist(prior$n_visitors)
# Calculate the probability that you will get 5 or more visitors
sum(prior$n_visitors >=5) / length(prior$n_visitors)
#hist(rbinom(10000, size = 100, prob = 0.2))
```


# Ejemplos

## uso de beta
la distribución beta es muy adaptable a cualquier rango de datos que tengamos
Explore usando la distribución Beta como una prioridad
La distribución Beta es una distribución de probabilidad útil cuando se desea la incertidumbre del modelo sobre un parámetro limitado entre 0 y 1. Aquí se explorará cómo los dos parámetros de la distribución Beta determinan su forma.

cuanto mayor sean los parametros más concentrada en estará la muestra enel centro
```{r}
# veamos la forma de beta con ambos parametros 1
# Explore using the rbeta function
beta_sample <- rbeta(n = 1000000, shape1 = 1, shape2 = 1)
# Visualize the results
hist(beta_sample)
# es como uniforme

# CUANTO MAS ALTO LOS PARAMETROS MAS CENTRADA
beta_sample <- rbeta(n = 1000000, shape1 = 100, shape2 = 100)
# Visualize the results
hist(beta_sample)

# CUANTO MAS ALTO SEA el p1 mas cerca de 1 y cuanto mas alto el p2 mas cerca de cero
beta_sample <- rbeta(n = 1000000, shape1 = 100, shape2 = 1)
# Visualize the results
hist(beta_sample)
beta_sample <- rbeta(n = 1000000, shape1 = 1, shape2 = 10)
# Visualize the results
hist(beta_sample)

```
si nos dicen que los anuncios habitualmente estan en el 5% y algunas veces en el 2 y en el 8
```{r}
n_draws <- 100000
n_ads_shown <- 100

# Change the prior on proportion_clicks
#proportion_clicks <-  runif(n_draws, min = 0.0, max = 0.2)
proportion_clicks <-  runif(n_draws, min = 0.0, max = 0.2)
n_visitors <- rbinom(n_draws, size = n_ads_shown, 
         prob = proportion_clicks)
prior <- data.frame(proportion_clicks, n_visitors)
posterior <- prior[prior$n_visitors == 13, ]

# This plots the prior and the posterior in the same plot
par(mfcol = c(2, 1))
hist(prior$proportion_clicks, 
     xlim = c(0, 0.25))
hist(posterior$proportion_clicks, 
     xlim = c(0, 0.25))
```
```{r}
n_draws <- 100000
n_ads_shown <- 100
proportion_clicks <- runif(n_draws, min = 0.0, max = 0.2)
n_visitors <- rbinom(n = n_draws, size = n_ads_shown, 
                     prob = proportion_clicks)
prior <- data.frame(proportion_clicks, n_visitors)

# Create the posteriors for video and text ads
posterior_video <- prior[prior$n_visitors == 13, ]
posterior_text <- prior[prior$n_visitors == 6, ]

# Visualize the posteriors
hist(posterior_video$proportion_clicks, xlim = c(0, 0.25))
hist(posterior_text$proportion_clicks, xlim = c(0, 0.25))
```

Calculando la diferencia posterior
Los porcentajes posteriores de anuncios de video y texto se han incluido en un solo marco de datos posterior. El motivo de [1: 4000] se debe a que proporcionalmente, estos clics no tienen la misma longitud, lo que necesitan ser cuando se colocan en un marco de datos.

Ahora es el momento de calcular la distribución de probabilidad posterior sobre la diferencia en la proporción de clics entre el anuncio de video y el anuncio de texto.
```{r}
posterior <- data.frame(
    video_prop = posterior_video$proportion_clicks[1:4000],
    text_prop  = posterior_text$proportion_click[1:4000])
    
# Calculate the posterior difference: video_prop - text_prop
posterior$prop_diff <- (posterior$video_prop - posterior$text_prop)

# Visualize prop_diff
hist(posterior$prop_diff)

# Summarize prop_diff
median(posterior$prop_diff)
sum(posterior$prop_diff>0)/length(posterior$prop_diff)
```

## decision analysis
Un pequeño análisis de decisión 1
Cada visitante gasta $ 2.53 en promedio, un anuncio de video cuesta $ 0.25 y un anuncio de texto cuesta $ 0.05. ¡Imaginemos la ganancia probable al usar anuncios de video y anuncios de texto!

El marco de datos posterior contiene la distribución de probabilidad sobre la proporción subyacente de clics para anuncios de video y anuncios de texto.

Agregue la columna posterior $ video_profit, que debe ser la distribución de probabilidad sobre la ganancia promedio que obtendrá al mostrar un anuncio de video. Es decir, la proporción subyacente de clics multiplicada por el gasto promedio menos el costo de mostrar el video.

```{r}
visitor_spend <- 2.53
video_cost <- 0.25
text_cost <- 0.05

# Add the column posterior$video_profit
posterior$video_profit<-posterior$video_prop*visitor_spend-video_cost
# Add the column posterior$text_profit
posterior$text_profit<-posterior$text_prop*visitor_spend-text_cost
# Visualize the video_profit and text_profit columns
hist(posterior$video_profit)
hist(posterior$text_profit)
```

## poison distribucion
nos da las distribucion media de click por unidad de tiempo

La distribución de Poisson
La distribución de Poisson simula un proceso donde el resultado es una cantidad de ocurrencias por día / año / área / unidad / etc. Antes de usarlo en un modelo Bayesiano, ¡exploradlo!

INSTRUCCIONES 1/4

La distribución de Poisson tiene un parámetro, la cantidad promedio de eventos por unidad. En R puede simular desde una distribución de Poisson utilizando rpois donde lambda es el número promedio de ocurrencias:

rpois (n = 10000, lambda = 3)
Usa el código de arriba para simular 10000 sorteos de una distribución de Poisson, asigna el resultado a x.
Visualice x usando un histograma (hist).
```{r}
# Simulate from a Poisson distribution and visualize the result
x<-rpois(n = 10000, lambda = 3)
hist(x)
```
Digamos que maneja un puesto de helados y en días nublados, en promedio, vende 11.5 helados. Es un día nublado.

Cambia la llamada de rpois para visualizar la distribución de probabilidad sobre cuántos helados venderás.
```{r}
# Simulate from a Poisson distribution and visualize the result
x<-rpois(n = 10000, lambda = 11.5)
hist(x)
```

Todavía es un día nublado y, lamentablemente, no alcanzarás un punto de equilibrio a menos que vendas 15 o más helados.

Suponiendo que el modelo de Poisson es razonable, use x para calcular la probabilidad de que llegue a un punto de equilibrio.
Consejo: para esto, debe calcular qué proporción de muestras en x son> = 15

```{r}
# Simulate from a Poisson distribution and visualize the result
x<-rpois(n = 10000, lambda = 11.5)
hist(x)
sum(x>=15)/length(x)
```

##Clics por día en lugar de clics por anuncio
Cuando coloca un banner en el sitio de su amigo, obtiene 19 clics en un día, ¿cuántos clics diarios debería esperar generar en promedio? Ahora, modifique su modelo, una pieza a la vez, para calcular esto.

INSTRUCCIONES 1/4

A la derecha está el código anterior para el modelo bayesiano binomial. Para acomodar los nuevos datos de banner, ahora va a cambiar el modelo para que use una distribución de Poisson.

Comience reemplazando la distribución anterior sobre proport_clicks por una anterior sobre mean_clicks. Realice una distribución previa uniforme (runif) de 0 a 80 clics por día.

```{r}
# Change this model so that it uses a Poisson distribution instead
n_draws <- 100000
n_ads_shown <- 100
proportion_clicks <- runif(n_draws, min = 0.0, max = 0.2)
n_visitors <- rbinom(n_draws, size = n_ads_shown, 
                     prob = proportion_clicks)
                     
prior <- data.frame(proportion_clicks, n_visitors)
posterior <- prior[prior$n_visitors == 13, ]

# nuevo con cambios
# Change this model so that it uses a Poisson distribution instead
n_draws <- 100000

#proportion_clicks <- runif(n_draws, min = 0.0, max = 0.2)
mean_clicks<-runif(n_draws, min = 0.0, max = 80)
n_visitors <- rpois(n_draws,lambda=mean_clicks )
                     
prior <- data.frame(mean_clicks, n_visitors)
posterior <- prior[prior$n_visitors == 19, ]

hist(prior$mean_clicks)
hist(posterior$mean_clicks)

```
# probabilidad conceptos.

Cards and the sum rule
A standard French-suited deck of playing cards contains 52 cards; 13 each of hearts (♥), spades (♠), clubs (♦), and diamonds (♣). Assuming that you have a well-shuffled deck in front of you, the probability of drawing any given card is 1/52 ≈ 1.92%.

Tarjetas y la regla de suma

Una baraja estándar de barajas para jugar contiene 52 cartas; 13 cada uno de corazones (♥), espadas (♠), palos (♦) y diamantes (♣). Suponiendo que tienes una baraja bien barajada frente a ti, la probabilidad de robar una carta determinada es de 1/52 ≈ 1.92%.Calcule la probabilidad de sacar cualquiera de los cuatro ases. Es decir, calcule la probabilidad de dibujar 🂡 o 🂱 o 🃁 o 🃑 usando la regla de 

```{r}
# Calculate the probability of drawing any of the four aces
# sacar cualquiera de los cuatrosde 4 ases
prob_to_draw_ace <- 4/52
# Calculate the probability of picking four aces in a row
prob_to_draw_four_aces <- 4/52*3/51*2/50*1/49
```
Utilice la regla del producto para calcular la probabilidad de elegir los cuatro ases en una fila desde la parte superior de un mazo bien barajado y asígnelo a prob_to_draw_four_aces.


# proceso de inferencia competo

Vams a crear un grid con todas las posibilidades combimadas de probabilidad del modelo de generación de anuncios y clicks

```{r}
n_ads_shown <- 100
proportion_clicks <- seq(0, 1, by = 0.01)
n_visitors <- seq(0, 100, by = 1)
pars <- expand.grid(proportion_clicks = proportion_clicks,
                    n_visitors = n_visitors)
head(pars)
pars$prior <- dunif(pars$proportion_clicks, min = 0, max = 0.2)
pars$likelihood <- dbinom(pars$n_visitors, 
    size = n_ads_shown, prob = pars$proportion_clicks)

# Add the column pars$probability and normalize it
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability/sum(pars$probability) 
```
```{r}
n_ads_shown <- 100
proportion_clicks <- seq(0, 1, by = 0.01)
n_visitors <- seq(0, 100, by = 1)
pars <- expand.grid(proportion_clicks = proportion_clicks,
                    n_visitors = n_visitors)
pars$prior <- dunif(pars$proportion_clicks, min = 0, max = 0.2)
pars$likelihood <- dbinom(pars$n_visitors, 
    size = n_ads_shown, prob = pars$proportion_clicks)
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)
# Condition on the data 
pars <- pars[pars$n_visitors==6,]
# Normalize again
pars$probability <- pars$probability/sum(pars$probability)
# Plot the posterior pars$probability
plot(x=pars$proportion_clicks, y=pars$probability, type = "h")
```

```{r}
#lo mismo simplificando código
# Simplify the code below by directly conditioning on the data
n_ads_shown <- 100
proportion_clicks <- seq(0, 1, by = 0.01)
n_visitors <- 6
pars <- expand.grid(proportion_clicks = proportion_clicks,
                    n_visitors = n_visitors)
pars$prior <- dunif(pars$proportion_clicks, min = 0, max = 0.2)
pars$likelihood <- dbinom(pars$n_visitors, 
    size = n_ads_shown, prob = pars$proportion_clicks)
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)

pars$probability <- pars$probability / sum(pars$probability)
plot(pars$proportion_clicks, pars$probability, type = "h")
```

## rnorm, dnorm, and the weight of newborns
Here is a small data set with the birth weights of six newborn babies in grams.

c(3164, 3362, 4435, 3542, 3578, 4529)
```{r}
# Explore using rnorm and dnorm
mu <- 3700
sigma <- 500

weight_distr <- rnorm(n = 100000, mean = mu, sd = sigma)
hist(weight_distr, 60, xlim = c(0, 6000), col = "lightgreen")

# Explore using rnorm and dnorm
mu <- 3700
sigma <- 500
weight<-seq(from = 0, to =6000 , by =100 )
weight_distr <- dnorm(weight,mean = mu, sd = sigma)
hist(weight_distr, 60, xlim = c(0, 6000), col = "lightgreen")

# Explore using rnorm and dnorm
mu <- 3700
sigma <- 500
weight<-seq(from = 0, to =6000 , by =100 )
likelihood <- dnorm(weight,mean = mu, sd = sigma)
plot(x=weight,y=likelihood, type="h")
```



```{r}
# modelo de temprestura del lago al completo
temp <- c(19, 23, 20, 17, 23)
mu <- seq(8, 30, by = 0.5)
sigma <- seq(0.1, 10, by = 0.3)
pars <- expand.grid(mu = mu, sigma = sigma)
pars$mu_prior <- dnorm(pars$mu, mean = 18, sd = 5)
pars$sigma_prior <- dunif(pars$sigma, min = 0, max = 10)
pars$prior <- pars$mu_prior * pars$sigma_prior
for(i in 1:nrow(pars)) {
    likelihoods <- dnorm(temp, pars$mu[i], pars$sigma[i])
    pars$likelihood[i] <- prod(likelihoods)
}
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)
```


## lo mismo con zoombies:

```{r}
# The IQ of a bunch of zombies
iq <- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 46)
# Defining the parameter grid
pars <- expand.grid(mu = seq(0, 150, length.out = 100), 
                    sigma = seq(0.1, 50, length.out = 100))
# Defining and calculating the prior density for each parameter combination
pars$mu_prior <- dnorm(pars$mu, mean = 100, sd = 100)
pars$sigma_prior <- dunif(pars$sigma, min = 0.1, max = 50)
pars$prior <- pars$mu_prior * pars$sigma_prior
# Calculating the likelihood for each parameter combination
for(i in 1:nrow(pars)) {
  likelihoods <- dnorm(iq, pars$mu[i], pars$sigma[i])
  pars$likelihood[i] <- prod(likelihoods)
}
# Calculate the probability of each parameter combination
pars$probability <- pars$likelihood * pars$prior
pars$probability <- pars$probability / sum(pars$probability)

#pintamos el resutado
library(lattice)
levelplot(probability ~ mu * sigma, data = pars)
```
## Muestreo desde el zombie posterior
Nuevamente, pars contiene el marco de datos que representa la distribución de IQ zombie posterior que calculó anteriormente. El código a la derecha dibuja muestra_indices: una muestra de números de fila (índices a.k.a.) del posterior. ¡Ahora, probemos de pars para calcular algunas medidas nuevas!

INSTRUCCIONES 1/4
25 XP
1
2
3
4
Use sample_indices para crear un nuevo marco de datos pars_sample de pars con las columnas mu y sigma extraídas de las filas indicadas por sample_indices.
Consejo: Si df es un marco de datos con muchas filas y columnas, aquí es cómo extraería las filas 1, 3 y 1 (nuevamente), y las columnas llamadas "altura" y "peso":

df [c (1,3,1), c ("altura", "peso")]
```{r}
head(pars)
sample_indices <- sample( nrow(pars), size = 10000,
    replace = TRUE, prob = pars$probability)
head(sample_indices)

# Sample from pars to calculate some new measures
pars_sample <- pars[sample_indices, c("mu", "sigma")]

# Visualize pars_sample
hist(pars_sample$mu)
# Calculate the 0.025, 0.5 and 0.975 quantiles of pars_sample$mu
quantile(pars_sample$mu, c(0.025,0.5, 0.975))
# con esto tendriamos la media y los valores con 95% de confianza
```

# BEST
BEST es un aquete que ayuda a hacer inferencia estadistica.


```{r}
library(BEST)
iq <- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 46)
fit <- BESTmcmc(iq)
plot(fit)
```
## Los MEJORES modelos y zombies en una dieta
La prueba t es un procedimiento estadístico clásico que se usa para comparar los medios de dos conjuntos de datos. En 2013, John Kruschke desarrolló una versión Bayesiana trucada de la prueba t que denominó BEST (que significa Estimación bayesiana que reemplaza la prueba t). Probemos BEST como se implementó en el paquete BEST.

Los zombis son estúpidos, pero tú y tus colegas en el Laboratorio Nacional de Investigación de Zombies están interesados en cómo la dieta afecta la inteligencia zombie. Has hecho un pequeño experimento donde midiste el IQ de 10 zombies con una dieta regular y 10 zombis con una dieta basada en el cerebro. La hipótesis es que los zombies que comen más cerebros rinden mejor en las pruebas de cociente intelectual. A la derecha, los datos del experimento se colocan en las variables iq_brains e iq_regular.

Calcule la diferencia de medias en IQ entre los dos grupos tomando la media de iq_brains menos la media de iq_regular. Recuerde que mean (iq_brains) calcula la media de muestra de iq_brains.

```{r}
# The IQ of zombies on a regular diet and a brain based diet.
iq_brains <- c(44, 52, 42, 66, 53, 42, 55, 57, 56, 51)
iq_regular <- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 46)

# Calculate the mean difference in IQ between the two groups
mean(iq_brains)-mean(iq_regular)
# Fit the BEST model to the data from both groups
library(BEST)
best_posterior<-BESTmcmc(iq_brains, iq_regular)
# Plot the model result
plot(best_posterior)
```


# Ejemplo

en una clase se mide a 5 de los niños la altura con el siguiente resultado:

altura<-c(120, 125, 140, 135, 133)

Se pide determinar la altura media de la clase con un 95% de probabilidad.
Usaremos el paquete BEST para estimar una funcion t (similar a la normal) que nos describa a partir de las evidencias de altura la media y desviación típica.

```{r}

altura<-c(120, 125, 140, 135, 133)
mean(altura)

library(BEST)
best_posterior<-BESTmcmc(altura)
plot(best_posterior)
```


# dibujo
```{r}

library(ggplot2)

df<-data.frame(x=0,y=0)
param=0.9

for(i in 2:100) {
    df[i,1]<-df[i-1,1]-(0.1*i)*cos(i)
    df[i,2]<-df[i-1,2]+(0.1*i)*sin(i)
    }

ggplot(df,aes(x,y))+
    geom_polygon(fill="darkblue")+
    theme_void()


for(i in 2:100) {
    df[i,1]<-df[i-1,1]+(0.9*i^2)*cos(i^2)
    df[i,2]<-df[i-1,2]+(0.9*i^2)*sin(i^2)
    }
```

